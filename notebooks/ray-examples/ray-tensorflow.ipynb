{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray with TensorFlow Test Notebook\n",
    "\n",
    "The purpose of this notebook is to confirm that Ray Train with TensorFlow works in ODH.\n",
    "\n",
    "This notebook primarily consists of an implementation of the TensorFlowlow example from the Ray docs on [Ray Train](https://docs.ray.io/en/latest/train/train.html). \n",
    "\n",
    "However, it has been modified to test that the Ray Train features for TensorFlow work in an Open Data Hub environment. We have also increased the number of samples and epochs run so that the speed up from Ray's distribution can be seen clearly.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 18:02:17.433073: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-26 18:02:17.433109: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import json\n",
    "import os\n",
    "\n",
    "import ray\n",
    "from ray.train import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We're going to connect to our Ray Cluster that was spun up for us as part of the [ray notebook image](https://github.com/thoth-station/ray-ml-notebook) we selected through the ODH spawner page. \n",
    "\n",
    "This cell should also run locally without a Ray cluster as it checks for the relevant environment variable \"RAY_CLUSTER\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClientContext(dashboard_url='10.128.3.96:8265', python_version='3.8.12', ray_version='1.12.1', ray_commit='4863e33856b54ccf8add5cbe75e41558850a1b75', protocol_version='2022-03-16', _num_clients=1, _context_to_restore=<ray.util.client._ClientContext object at 0x7f01f1a36370>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init('ray://{ray_head}:10001'.format(ray_head=os.environ['RAY_CLUSTER']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define our data and model architecture\n",
    "\n",
    "For this example we will be using the well known MNIST character recognition dataset to train a classification model using a convolutional deep neural network (2 layers). However, for this particular notebook, we don't really care about the particular dataset or machine learning task. The goal here is to prove that our open data hub deployment can run Ray Train jobs with TensorFlow.\n",
    "\n",
    "First thing we will do is create a function that returns a TensorFlow Dataset object from the mnist dataset provided by tensorflow. We can use this Dataset object to iterate over batches of data during training. \n",
    "\n",
    "Next we'll define our TensorFlow model. This will be a convolutional neural network with 2 hidden layers, a 2D convolutional later, and a Dense layer. The model will taken in a 28 x 28 array and out put a 1 x 10 array representing the 10 possible categorize of digits our model will choose between.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_dataset(batch_size):\n",
    "    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "    # The `x` arrays are in uint8 and have values in the [0, 255] range.\n",
    "    # You need to convert them to float32 with values in the [0, 1] range.\n",
    "    x_train = x_train / np.float32(255)\n",
    "    y_train = y_train.astype(np.int64)\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (x_train, y_train)).shuffle(6000).repeat().batch(batch_size)\n",
    "    return train_dataset\n",
    "\n",
    "\n",
    "def build_and_compile_cnn_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Distributed Training \n",
    "\n",
    "Before we look at Ray and it's distributed training, let's start by training a single worker model here first to give us a baseline and something compare our distributed model to in a minute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func():\n",
    "    batch_size = 64\n",
    "    single_worker_dataset = mnist_dataset(batch_size)\n",
    "    single_worker_model = build_and_compile_cnn_model()\n",
    "    single_worker_model.fit(single_worker_dataset, epochs=3, steps_per_epoch=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 18:02:22.511309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 18:02:22.513926: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-26 18:02:22.513990: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-26 18:02:22.514039: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-26 18:02:22.514088: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-07-26 18:02:22.514135: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-07-26 18:02:22.514197: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-26 18:02:22.514247: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-26 18:02:22.514295: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-07-26 18:02:22.514306: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-07-26 18:02:22.514861: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 6/70 [=>............................] - ETA: 0s - loss: 2.3094 - accuracy: 0.0807 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 18:02:22.972882: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 1s 11ms/step - loss: 2.2817 - accuracy: 0.1237\n",
      "Epoch 2/3\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 2.2090 - accuracy: 0.4051\n",
      "Epoch 3/3\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 2.1340 - accuracy: 0.5714\n",
      "CPU times: user 12.8 s, sys: 1.4 s, total: 14.2 s\n",
      "Wall time: 3.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Training\n",
    "\n",
    "Great, now let's re-write our training function a bit so that it's compatible with Ray Train. To update this function we need to:\n",
    "* Add `TF_CONFIG` environment variable that ray we handle for use\n",
    "* Add `num_workers` defined as the length of workers in tf_config\n",
    "* Set the distributed learning strategy as MultiWorkerMirroredStrategy\n",
    "* Add a `global_batch_size`\n",
    "* Add a `with strategy.scope()` statement to place our model building step \n",
    "* Finally, add a `ray.train.save_checkpoint` so that we can use our trained model for inference later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func_distributed():\n",
    "    per_worker_batch_size = 64\n",
    "    # This environment variable will be set by Ray Train.\n",
    "    tf_config = json.loads(os.environ['TF_CONFIG'])\n",
    "    num_workers = len(tf_config['cluster']['worker'])\n",
    "\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "\n",
    "    global_batch_size = per_worker_batch_size * num_workers\n",
    "    multi_worker_dataset = mnist_dataset(global_batch_size)\n",
    "\n",
    "    with strategy.scope():\n",
    "        # Model building/compiling need to be within `strategy.scope()`.\n",
    "        multi_worker_model = build_and_compile_cnn_model()\n",
    "\n",
    "    multi_worker_model.fit(multi_worker_dataset, epochs=3, steps_per_epoch=70, verbose=0)\n",
    "    ray.train.save_checkpoint(epoch=2, model_weights=multi_worker_model.get_weights()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we instantiate our Ray `Trainer` that we use to manage which backend we want (pytorch, tensorflow or horovod) and the number of workers we will want to use. Below we will use 2 workers. Here we can also define whether or not we want to use a gpu for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 18:02:25,451\tINFO trainer.py:223 -- Trainer logs will be logged in: /opt/app-root/src/ray_results/train_2022-07-26_18-02-25\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(backend='tensorflow', num_workers=2, use_gpu=True, max_retries=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Let's run our training function and see how long it takes with Ray Train's distribution functionality. Please note, there is an overhead cost associated with starting the Trainer. So let's time that separately from our actual training function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(BackendExecutor pid=1668)\u001b[0m 2022-07-26 18:02:28.723785: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(BackendExecutor pid=1668)\u001b[0m 2022-07-26 18:02:28.723820: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=390, ip=10.131.0.36)\u001b[0m 2022-07-26 18:02:31.896774: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=390, ip=10.131.0.36)\u001b[0m 2022-07-26 18:02:31.896818: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=1706)\u001b[0m 2022-07-26 18:02:31.902748: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=1706)\u001b[0m 2022-07-26 18:02:31.902791: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.9 ms, sys: 3.17 ms, total: 20.1 ms\n",
      "Wall time: 6.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = trainer.run(train_func_distributed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Times will vary depending on where you are running this notebook, the sample size you selected above, the number of epochs and the number of workers, but if everything worked correctly and you are using a distributed ray cluster, the Wall time for the `train.run()` function above should be significantly less than that for the non-distributed training run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.67 ms, sys: 129 Âµs, total: 2.8 ms\n",
      "Wall time: 35.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "We've trained a model! Now we need to make sure we can use it for inference. Below we'll perform to quick examples of using the trained model. First, we'll generate a brand new data set the same way we did above, and use accuracy and sparse categorical cross entropy loss (same evaluation makes from training) to evaluate the model's performance on a new batch of 64 inputs.\n",
    "\n",
    "We are not particularly concerned about the values here, but are simply illustrating that we can perform inference with our newly trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.latest_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = build_and_compile_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference.set_weights(results[\"model_weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = mnist_dataset(64)\n",
    "ds = ds.take(1)\n",
    "for i in ds:\n",
    "    ds = i\n",
    "X = ds[0]\n",
    "y = ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0986 - accuracy: 0.5469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0986456871032715, 0.546875]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference.evaluate(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are reading this cell and there are no errors above, then you have successfully run a Ray Train TensorFlow notebook in a distributed environment with Open Data Hub!  Yeahh!! :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.util.disconnect()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e34450d332bd313b8f818cb5ed04e25933b13de9c0d7b662ddcaf48d79a536f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
